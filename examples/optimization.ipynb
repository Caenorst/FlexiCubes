{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Based Mesh Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FlexiCubes is an isosurface representation designed for gradient-based mesh optimization, where we iteratively\n",
    "optimize for a 3D surface mesh by representing it as the isosurface of a scalar field. Essentially, this paradigm allows objectives to be directly evaluated on the extracted surface, while offering the flexibility to optimize over meshes with different topologies.\n",
    "\n",
    "In this tutorial, we demonstrate how to reconstruct an unknown mesh using multiview masks and depth supervision with FlexiCubes. Note that in our paper, we demonstrate more objectives that FlexiCubes can optimize for a variety of applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the necessary packages and defining the hyperparameters for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import render\n",
    "import loss\n",
    "\n",
    "import kaolin as kal\n",
    "\n",
    "\n",
    "iter = 300\n",
    "batch = 8\n",
    "train_res = [2048, 2048]\n",
    "learning_rate = 0.01\n",
    "voxel_grid_res = 64\n",
    "device = 'cuda'\n",
    "sdf_regularizer = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the reference mesh and initialize a FlexiCubes object. We will be optimizing its SDF, weights, and deformations to fit the reference mesh. In this example, we are directly applying gradient descents on these parameters. Alternatively, you can parameterize them using a network of your choice and optimize the network weights instead (Please refer to the GET3D GitHub page for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh = kal.io.obj.import_mesh('data/inputmodels/block.obj').cuda()\n",
    "vertices = gt_mesh.vertices\n",
    "vmin, vmax = vertices.min(dim=0)[0], vertices.max(dim=0)[0]\n",
    "scale = 1.8 / torch.max(vmax - vmin).item()\n",
    "vertices = vertices - (vmax + vmin) / 2 # Center mesh on origin\n",
    "gt_mesh.vertices = vertices * scale # Rescale to [-0.9, 0.9]\n",
    "\n",
    "fc = kal.non_commercial.FlexiCubes(device)\n",
    "x_nx3, cube_fx8 = fc.construct_voxel_grid(voxel_grid_res)\n",
    "x_nx3 *= 2 # scale up the grid so that it's larger than the target object\n",
    "sdf = torch.rand_like(x_nx3[:,0]) - 0.1 # randomly initialize SDF\n",
    "sdf    = torch.nn.Parameter(sdf.clone().detach(), requires_grad=True)\n",
    "# set per-cube learnable weights to zeros\n",
    "weight = torch.zeros((cube_fx8.shape[0], 21), dtype=torch.float, device='cuda') \n",
    "weight    = torch.nn.Parameter(weight.clone().detach(), requires_grad=True)\n",
    "deform = torch.nn.Parameter(torch.zeros_like(x_nx3), requires_grad=True)\n",
    "\n",
    "#  Retrieve all the edges of the voxel grid; these edges will be utilized to \n",
    "#  compute the regularization loss in subsequent steps of the process.\n",
    "all_edges = cube_fx8[:, fc.cube_edges].reshape(-1, 2) \n",
    "grid_edges = torch.unique(all_edges, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = render.get_rotate_camera(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the mesh from the initial FlexiCubes grid to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb0d53b401a4846b4571ebcb079fa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(height=512, width=1024), interactive(children=(FloatLogSlider(value=0.3981071705534972, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09aa6b3b11a943018ab276f739d20b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_verts = x_nx3 + (2-1e-8) / (voxel_grid_res * 2) * torch.tanh(deform) # apply deformation to the grid vertices\n",
    "vertices, faces, L_dev = fc(\n",
    "    grid_verts, sdf, cube_fx8, voxel_grid_res, beta=weight[:,:12], alpha=weight[:,12:20],\n",
    "    gamma_f=weight[:,20], training=False) # run isosurfacing to extract the mesh\n",
    "init_mesh = kal.rep.SurfaceMesh(vertices=vertices, faces=faces)\n",
    "\n",
    "render.SplitVisualizer(init_mesh, gt_mesh, 512, 512).show(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the initial mesh topology (on the left) is very different from our reference (on the right). Don't worry, it will converge to the reference in the end! \n",
    "\n",
    "The last thing before we start the optimization is to set up the optimizers and a differentiable renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(iter):\n",
    "    return max(0.0, 10 ** (-(iter) * 0.0002)) # Exponential falloff from [1.0, 0.1] over 5k epochs.    \n",
    "optimizer = torch.optim.Adam([sdf, weight, deform], lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: lr_schedule(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's execute the actual optimization loop. At every iteration, we perform the following steps:\n",
    "\n",
    "* Sample random camera poses to render both the reference and ground truth images.\n",
    "* Extract the mesh with FlexiCubes, as we did above.\n",
    "* Render the meshes and evaluate the reconstruction and regularization losses (please see inline comments for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 300/300 [00:21<00:00, 14.13it/s]\n"
     ]
    }
   ],
   "source": [
    "intermediate_results = [init_mesh]\n",
    "for it in tqdm.tqdm(range(iter)): \n",
    "    optimizer.zero_grad()\n",
    "    # sample random camera poses\n",
    "    cameras = render.get_random_camera_batch(batch, iter_res=train_res, device=device)\n",
    "    \n",
    "    # render gt mesh at sampled views\n",
    "    target = render.render_mesh(gt_mesh, cameras, train_res)\n",
    "\n",
    "    # extract and render FlexiCubes mesh\n",
    "    grid_verts = x_nx3 + (2-1e-8) / (voxel_grid_res * 2) * torch.tanh(deform)\n",
    "    vertices, faces, L_dev = fc(\n",
    "        grid_verts, sdf, cube_fx8, voxel_grid_res, beta=weight[:,:12], alpha=weight[:,12:20],\n",
    "        gamma_f=weight[:,20], training=True)\n",
    "    flexicubes_mesh = kal.rep.SurfaceMesh(vertices=vertices, faces=faces)\n",
    "    buffers = render.render_mesh(flexicubes_mesh, cameras, train_res)\n",
    "\n",
    "    # evaluate reconstruction loss\n",
    "    mask_loss = (buffers['mask'] - target['mask']).abs().mean() # mask loss\n",
    "    depth_loss = (((((buffers['depth'] - (target['depth']))* target['mask'])**2).sum(-1)+1e-8)).sqrt().mean() * 10 # depth loss\n",
    "    # evaluate regularization losses\n",
    "    t_iter = it / iter\n",
    "    # this is the regularization loss described in Equation 2 of the nvdiffrec paper by Munkberg et al., which serves to remove internal floating elements that are not visible to the user.\n",
    "    sdf_weight = sdf_regularizer - (sdf_regularizer - sdf_regularizer/20)*min(1.0, 4.0 * t_iter)\n",
    "    reg_loss = loss.sdf_reg_loss(sdf, grid_edges).mean() * sdf_weight \n",
    "\n",
    "    reg_loss += L_dev.mean() * 0.5 # L_dev as in Equation 8 of our paper\n",
    "    reg_loss += (weight[:,:20]).abs().mean() * 0.1 # regularize weights to be zeros to improve the stability of the optimization process\n",
    "    total_loss = mask_loss + depth_loss + reg_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (it + 1) % 20 == 0: # save intermediate results every 100 iters\n",
    "        with torch.no_grad():\n",
    "            # run the mesh extraction again with the parameter 'training=False' so that each quadrilateral face is divided into two triangles, as opposed to the four triangles during the training phase.\n",
    "            vertices, faces, L_dev = fc(\n",
    "                grid_verts, sdf, cube_fx8, voxel_grid_res, beta=weight[:,:12], alpha=weight[:,12:20], gamma_f=weight[:,20], training=False)\n",
    "            intermediate_results.append(kal.rep.SurfaceMesh(vertices, faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize how the isosurface of FlexiCubes evolves during optimization. As you can see, it converges smoothly to the reference mesh, successfully recovering all sharp features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2995a7bec143049f315ca6462397ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), interactive(children=(FloatLogSlider(value=0.3981071705534972, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3174cb213cad4044b5ec6de2e869f2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render.TimelineVisualizer(intermediate_results, 512, 512).show(camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
